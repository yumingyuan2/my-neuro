# audio_proucess.py - ç®€æ´ç‰ˆé‡æ„
from queue import Queue
import pygame
from io import BytesIO
import requests
import time
import threading
import tempfile
import os
import keyboard
import wave
import logging

# å¯¼å…¥äº‹ä»¶æ€»çº¿
try:
    from UI.simple_event_bus import event_bus, Events

    HAS_EVENT_BUS = True
except ImportError:
    HAS_EVENT_BUS = False

logger = logging.getLogger("audio_player")


class AudioProcess:
    def tts_inference(self, text):
        """åªåšTTSæ¨ç†ï¼Œè¿”å›éŸ³é¢‘æ•°æ®"""
        data = {'text': text, 'text_language': 'zh'}
        url = 'http://127.0.0.1:5000'
        response = requests.post(url, json=data)
        return response.content

    def get_audio_duration(self, audio_data):
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(audio_data)
                temp_path = temp_file.name

            with wave.open(temp_path, 'rb') as wav_file:
                frames = wav_file.getnframes()
                sample_rate = wav_file.getframerate()
                duration = frames / sample_rate

            os.remove(temp_path)
            return duration
        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 0.0

    def play_audio(self, audio_data):
        """åªæ’­æ”¾éŸ³é¢‘æ•°æ®"""
        if pygame.mixer.get_init():
            pygame.mixer.music.stop()
            pygame.mixer.quit()

        audio_buffer = BytesIO(audio_data)
        pygame.mixer.init()
        pygame.mixer.music.load(audio_buffer)
        pygame.mixer.music.play()

        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)


class AudioPlayer:
    def __init__(self, live_model=None, emotion_handler=None):
        self.audio_process = AudioProcess()
        self.text_queue = Queue()
        self.audio_queue = Queue()
        self.text_buffer = ''
        self.punc = {',', 'ï¼Œ', 'ã€‚', 'ï¼', '!', '?'}
        self.live_model = live_model
        self.emotion_handler = emotion_handler
        self.is_interrupted = False

        self.sync_data_queue = Queue()

        self.start_tts_thread()
        keyboard.add_hotkey('ctrl+i', self.interrupt_audio)

        # ğŸ”¥ æ–°å¢ï¼šè®¢é˜…äº‹ä»¶
        if HAS_EVENT_BUS:
            event_bus.subscribe("audio_interrupt", self._handle_interrupt_event)
            event_bus.subscribe("tts_request", self._handle_tts_request)

    def _handle_interrupt_event(self, data=None):
        """å¤„ç†æ‰“æ–­äº‹ä»¶"""
        self.interrupt_audio()

    def _handle_tts_request(self, data):
        """å¤„ç†TTSè¯·æ±‚äº‹ä»¶"""
        text = data.get('text', '')
        if text.strip():
            self.add_text_to_queue(text)

    def clear_queue(self):
        """æ¸…ç©ºæ‰€æœ‰é˜Ÿåˆ—"""
        while not self.text_queue.empty():
            self.text_queue.get()
        while not self.audio_queue.empty():
            self.audio_queue.get()
        while not self.sync_data_queue.empty():
            self.sync_data_queue.get()

    def interrupt_audio(self):
        """æ‰“æ–­æ“ä½œ"""
        print("ğŸ”‡ éŸ³é¢‘è¢«æ‰“æ–­")
        pygame.mixer.music.stop()
        self.clear_queue()
        self.is_interrupted = True

        # ğŸ”¥ å‘å¸ƒæ‰“æ–­äº‹ä»¶
        if HAS_EVENT_BUS:
            event_bus.publish("audio_interrupted", {"timestamp": time.time()})

        if self.emotion_handler:
            self.emotion_handler.stop_audio_sync()

    def cut_text(self, ai_content):
        """å¤„ç†æµå¼æ–‡æœ¬è¾“å…¥"""
        self.is_interrupted = False
        for char in ai_content:
            if self.is_interrupted:
                break
            self.text_buffer += char
            if char in self.punc:
                self.process_text_segment(self.text_buffer)
                self.text_buffer = ''

    def finish_current_text(self):
        """åœ¨AIå›å¤å®Œå…¨ç»“æŸæ—¶è°ƒç”¨ï¼Œå¤„ç†å‰©ä½™æ–‡æœ¬"""
        if self.text_buffer.strip() and not self.is_interrupted:
            self.process_text_segment(self.text_buffer.strip())
            self.text_buffer = ''

    def process_text_segment(self, text_segment):
        """å¤„ç†æ–‡æœ¬æ®µè½"""
        if not text_segment.strip():
            return

        # ğŸ”¥ å‘å¸ƒæ–‡æœ¬å¤„ç†äº‹ä»¶
        if HAS_EVENT_BUS:
            event_bus.publish("text_processing", {"text": text_segment})

        # å¦‚æœæœ‰æƒ…ç»ªå¤„ç†å™¨ï¼Œé¢„å¤„ç†æ–‡æœ¬
        if self.emotion_handler:
            processed_data = self.emotion_handler.prepare_text_for_audio(text_segment)
            clean_text = processed_data['clean_text']
            emotion_markers = processed_data['emotion_markers']

            sync_data = {
                'original_text': text_segment,
                'clean_text': clean_text,
                'emotion_markers': emotion_markers
            }
            self.sync_data_queue.put(sync_data)
        else:
            sync_data = {
                'original_text': text_segment,
                'clean_text': text_segment,
                'emotion_markers': []
            }
            self.sync_data_queue.put(sync_data)

    def run_tts(self):
        """TTSè½¬æ¢çº¿ç¨‹"""
        while True:
            sync_data = self.sync_data_queue.get()

            if self.is_interrupted:
                continue

            clean_text = sync_data['clean_text']
            emotion_markers = sync_data['emotion_markers']

            # ğŸ”¥ å‘å¸ƒTTSå¼€å§‹äº‹ä»¶
            if HAS_EVENT_BUS:
                event_bus.publish("tts_start", {"text": clean_text})

            audio_data = self.audio_process.tts_inference(clean_text)
            audio_duration = self.audio_process.get_audio_duration(audio_data)

            audio_item = {
                'audio_data': audio_data,
                'clean_text': clean_text,
                'emotion_markers': emotion_markers,
                'audio_duration': audio_duration
            }

            self.audio_queue.put(audio_item)

    def play_audio_data(self):
        """éŸ³é¢‘æ’­æ”¾çº¿ç¨‹"""
        while True:
            audio_item = self.audio_queue.get()

            if self.is_interrupted:
                continue

            audio_data = audio_item['audio_data']
            clean_text = audio_item['clean_text']
            emotion_markers = audio_item['emotion_markers']
            audio_duration = audio_item['audio_duration']

            try:
                # ğŸ”¥ å‘å¸ƒéŸ³é¢‘æ’­æ”¾å¼€å§‹äº‹ä»¶
                if HAS_EVENT_BUS:
                    event_bus.publish("audio_play_start", {
                        "duration": audio_duration,
                        "text": clean_text
                    })

                # å¯åŠ¨æƒ…ç»ªåŒæ­¥
                if self.emotion_handler and emotion_markers:
                    self.emotion_handler.start_audio_sync(
                        clean_text,
                        emotion_markers,
                        audio_duration
                    )

                # å¦‚æœæœ‰Live2Dæ¨¡å‹ï¼Œå¯åŠ¨å˜´å‹åŒæ­¥
                if self.live_model:
                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                        temp_file.write(audio_data)
                        temp_path = temp_file.name

                    try:
                        # ğŸ”¥ å‘å¸ƒå˜´å‹åŒæ­¥äº‹ä»¶
                        if HAS_EVENT_BUS:
                            event_bus.publish("lip_sync_start", {"audio_path": temp_path})

                        self.live_model.start_lip_sync(temp_path)
                        self.audio_process.play_audio(audio_data)
                    finally:
                        if os.path.exists(temp_path):
                            os.remove(temp_path)
                else:
                    self.audio_process.play_audio(audio_data)

                # ğŸ”¥ å‘å¸ƒéŸ³é¢‘æ’­æ”¾å®Œæˆäº‹ä»¶
                if HAS_EVENT_BUS:
                    event_bus.publish("audio_play_complete", {"text": clean_text})

                # åœæ­¢æƒ…ç»ªåŒæ­¥
                if self.emotion_handler:
                    self.emotion_handler.stop_audio_sync()

            except pygame.error as e:
                continue
            except Exception as e:
                if self.emotion_handler:
                    self.emotion_handler.stop_audio_sync()

    def add_text_to_queue(self, text):
        """æ·»åŠ æ–‡æœ¬åˆ°é˜Ÿåˆ—ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        self.is_interrupted = False
        self.process_text_segment(text)

    def start_tts_thread(self):
        """å¯åŠ¨TTSåŒçº¿ç¨‹"""
        run_tts_thread = threading.Thread(target=self.run_tts, daemon=True)
        play_audio_data_thread = threading.Thread(target=self.play_audio_data, daemon=True)
        run_tts_thread.start()
        play_audio_data_thread.start()

    def set_live_model(self, live_model):
        """è®¾ç½®Live2Dæ¨¡å‹"""
        self.live_model = live_model

    def set_emotion_handler(self, emotion_handler):
        """è®¾ç½®æƒ…ç»ªå¤„ç†å™¨"""
        self.emotion_handler = emotion_handler

from queue import Queue
import pygame
from io import BytesIO
import requests
import time
import threading
import tempfile
import os
import keyboard
import wave
import logging

logger = logging.getLogger("audio_player")

class AudioProcess:

    def tts_inference(self, text):
        """åªåšTTSæ¨ç†ï¼Œè¿”å›éŸ³é¢‘æ•°æ®"""
        data = {'text': text, 'text_language': 'zh'}
        url = 'http://127.0.0.1:5000'
        response = requests.post(url, json=data)
        return response.content

    def get_audio_duration(self, audio_data):
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            # å°†éŸ³é¢‘æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(audio_data)
                temp_path = temp_file.name

            # è¯»å–éŸ³é¢‘æ–‡ä»¶è·å–æ—¶é•¿
            with wave.open(temp_path, 'rb') as wav_file:
                frames = wav_file.getnframes()
                sample_rate = wav_file.getframerate()
                duration = frames / sample_rate

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_path)
            return duration
        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 0.0

    def play_audio(self, audio_data):
        """åªæ’­æ”¾éŸ³é¢‘æ•°æ®"""
        if pygame.mixer.get_init():
            pygame.mixer.music.stop()
            pygame.mixer.quit()

        audio_buffer = BytesIO(audio_data)
        pygame.mixer.init()
        pygame.mixer.music.load(audio_buffer)
        pygame.mixer.music.play()

        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)

    def play_merge_audio(self, text):
        """è¾“å…¥æ–‡æœ¬æ’­æ”¾éŸ³é¢‘"""
        audio_data = self.tts_inference(text)
        self.play_audio(audio_data)


class AudioPlayer:

    def __init__(self, live_model=None, emotion_handler=None):
        self.audio_process = AudioProcess()
        self.text_queue = Queue()
        self.audio_queue = Queue()
        self.text_buffer = ''
        self.punc = {',', 'ï¼Œ', 'ã€‚', 'ï¼', '!', '?'}
        self.stream_text = None
        self.live_model = live_model  # Live2Dæ¨¡å‹å¼•ç”¨
        self.emotion_handler = emotion_handler  # æƒ…ç»ªå¤„ç†å™¨å¼•ç”¨
        self.is_interrupted = False  # æ‰“æ–­æ ‡å¿—ä½
        
        # æ–°å¢ï¼šåŒæ­¥ç›¸å…³
        self.sync_data_queue = Queue()  # å­˜å‚¨åŒæ­¥æ•°æ®çš„é˜Ÿåˆ—
        
        self.start_tts_thread()
        keyboard.add_hotkey('ctrl+i', self.interrupt_audio)

    def clear_queue(self):
        """æ¸…ç©ºæ‰€æœ‰é˜Ÿåˆ—"""
        while not self.text_queue.empty():
            self.text_queue.get()
        while not self.audio_queue.empty():
            self.audio_queue.get()
        while not self.sync_data_queue.empty():
            self.sync_data_queue.get()

    def interrupt_audio(self):
        """æ‰“æ–­æ“ä½œ"""
        print("ğŸ”‡ éŸ³é¢‘è¢«æ‰“æ–­")
        pygame.mixer.music.stop()  # åœæ­¢å½“å‰æ’­æ”¾
        self.clear_queue()  # æ¸…ç©ºé˜Ÿåˆ—
        self.is_interrupted = True  # è®¾ç½®æ‰“æ–­æ ‡å¿—
        
        # åœæ­¢æƒ…ç»ªåŒæ­¥
        if self.emotion_handler:
            self.emotion_handler.stop_audio_sync()

    def cut_text(self, ai_content):
        """å¤„ç†æµå¼æ–‡æœ¬è¾“å…¥"""
        self.is_interrupted = False  # å¼€å§‹æ–°å¯¹è¯æ—¶é‡ç½®æ‰“æ–­çŠ¶æ€
        for char in ai_content:
            if self.is_interrupted:  # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
                break
            self.text_buffer += char
            if char in self.punc:
                # å¤„ç†åŒ…å«æƒ…ç»ªæ ‡ç­¾çš„æ–‡æœ¬æ®µè½
                self.process_text_segment(self.text_buffer)
                self.text_buffer = ''

    def finish_current_text(self):
        """åœ¨AIå›å¤å®Œå…¨ç»“æŸæ—¶è°ƒç”¨ï¼Œå¤„ç†å‰©ä½™æ–‡æœ¬"""
        if self.text_buffer.strip() and not self.is_interrupted:
            # å¤„ç†æœ€åä¸€æ®µæ–‡æœ¬
            self.process_text_segment(self.text_buffer.strip())
            self.text_buffer = ''

    def process_text_segment(self, text_segment):
        """
        å¤„ç†æ–‡æœ¬æ®µè½ï¼Œæå–æƒ…ç»ªæ ‡ç­¾å¹¶å‡†å¤‡åŒæ­¥æ•°æ®
        
        Args:
            text_segment: æ–‡æœ¬æ®µè½
        """
        if not text_segment.strip():
            return
        
        # å¦‚æœæœ‰æƒ…ç»ªå¤„ç†å™¨ï¼Œé¢„å¤„ç†æ–‡æœ¬
        if self.emotion_handler:
            processed_data = self.emotion_handler.prepare_text_for_audio(text_segment)
            clean_text = processed_data['clean_text']
            emotion_markers = processed_data['emotion_markers']
            
            # å°†æ–‡æœ¬å’Œæƒ…ç»ªæ ‡è®°ä¿¡æ¯ä¸€èµ·æ”¾å…¥é˜Ÿåˆ—
            sync_data = {
                'original_text': text_segment,
                'clean_text': clean_text,
                'emotion_markers': emotion_markers
            }
            self.sync_data_queue.put(sync_data)
            
            # é™é»˜å¤„ç†ï¼Œä¸è¾“å‡ºæ—¥å¿—
        else:
            # æ²¡æœ‰æƒ…ç»ªå¤„ç†å™¨ï¼Œç›´æ¥å¤„ç†
            sync_data = {
                'original_text': text_segment,
                'clean_text': text_segment,
                'emotion_markers': []
            }
            self.sync_data_queue.put(sync_data)

    def run_tts(self):
        """TTSè½¬æ¢çº¿ç¨‹ - ä»åŒæ­¥æ•°æ®é˜Ÿåˆ—å–æ•°æ®ï¼Œè½¬æ¢æˆéŸ³é¢‘"""
        while True:
            # ä»åŒæ­¥æ•°æ®é˜Ÿåˆ—é‡Œé¢å–å‡ºæ•°æ®
            sync_data = self.sync_data_queue.get()

            # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
            if self.is_interrupted:
                continue

            clean_text = sync_data['clean_text']
            emotion_markers = sync_data['emotion_markers']

            # ä½¿ç”¨çº¯æ–‡æœ¬è¿›è¡ŒTTSæ¨ç†
            audio_data = self.audio_process.tts_inference(clean_text)
            
            # è·å–éŸ³é¢‘æ—¶é•¿
            audio_duration = self.audio_process.get_audio_duration(audio_data)
            
            # å°†éŸ³é¢‘æ•°æ®å’ŒåŒæ­¥ä¿¡æ¯ä¸€èµ·æ”¾å…¥éŸ³é¢‘é˜Ÿåˆ—
            audio_item = {
                'audio_data': audio_data,
                'clean_text': clean_text,
                'emotion_markers': emotion_markers,
                'audio_duration': audio_duration
            }
            
            self.audio_queue.put(audio_item)

    def play_audio_data(self):
        """éŸ³é¢‘æ’­æ”¾çº¿ç¨‹ - æ’­æ”¾éŸ³é¢‘å¹¶å¯åŠ¨æƒ…ç»ªåŒæ­¥"""
        while True:
            # ä»éŸ³é¢‘é˜Ÿåˆ—é‡Œé¢å–å‡ºéŸ³é¢‘é¡¹
            audio_item = self.audio_queue.get()

            # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
            if self.is_interrupted:
                continue

            audio_data = audio_item['audio_data']
            clean_text = audio_item['clean_text']
            emotion_markers = audio_item['emotion_markers']
            audio_duration = audio_item['audio_duration']

            try:
                # å¯åŠ¨æƒ…ç»ªåŒæ­¥ï¼ˆåœ¨éŸ³é¢‘æ’­æ”¾ä¹‹å‰ï¼‰
                if self.emotion_handler and emotion_markers:
                    self.emotion_handler.start_audio_sync(
                        clean_text, 
                        emotion_markers, 
                        audio_duration
                    )
                # é™é»˜å¯åŠ¨æƒ…ç»ªåŒæ­¥

                # å¦‚æœæœ‰Live2Dæ¨¡å‹ï¼Œå¯åŠ¨å˜´å‹åŒæ­¥
                if self.live_model:
                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                        temp_file.write(audio_data)
                        temp_path = temp_file.name

                    try:
                        self.live_model.start_lip_sync(temp_path)
                        # æ’­æ”¾éŸ³é¢‘
                        self.audio_process.play_audio(audio_data)
                    finally:
                        if os.path.exists(temp_path):
                            os.remove(temp_path)
                else:
                    # æ²¡æœ‰Live2Dæ¨¡å‹ï¼Œåªæ’­æ”¾éŸ³é¢‘
                    self.audio_process.play_audio(audio_data)

                # éŸ³é¢‘æ’­æ”¾ç»“æŸåï¼Œåœæ­¢æƒ…ç»ªåŒæ­¥
                if self.emotion_handler:
                    self.emotion_handler.stop_audio_sync()

            except pygame.error as e:
                # é™é»˜è·³è¿‡åéŸ³é¢‘
                continue  # é™é»˜è·³è¿‡åéŸ³é¢‘
            except Exception as e:
                # é™é»˜å¤„ç†é”™è¯¯
                # ç¡®ä¿åœæ­¢æƒ…ç»ªåŒæ­¥
                if self.emotion_handler:
                    self.emotion_handler.stop_audio_sync()

    def add_text_to_queue(self, text):
        """æ·»åŠ æ–‡æœ¬åˆ°é˜Ÿåˆ—ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        self.is_interrupted = False
        self.process_text_segment(text)

    def start_tts_thread(self):
        """å¯åŠ¨TTSåŒçº¿ç¨‹"""
        run_tts_thread = threading.Thread(target=self.run_tts, daemon=True)
        play_audio_data_thread = threading.Thread(target=self.play_audio_data, daemon=True)
        run_tts_thread.start()
        play_audio_data_thread.start()

    def set_live_model(self, live_model):
        """è®¾ç½®Live2Dæ¨¡å‹"""
        self.live_model = live_model

    def set_emotion_handler(self, emotion_handler):
        """è®¾ç½®æƒ…ç»ªå¤„ç†å™¨"""
        self.emotion_handler = emotion_handler

import sounddevice as sd
import numpy as np
import requests
import keyboard
import wave
import websockets.legacy.client as websockets_client
import json
import asyncio
from io import BytesIO
from queue import Queue
import threading
import time


class AudioSystem:
    def __init__(self, parent_neuro=None):
        # *** ä¿å­˜MyNeuroå®ä¾‹çš„å¼•ç”¨ ***
        self.parent_neuro = parent_neuro

        # æ–°å¢ï¼šéº¦å…‹é£çŠ¶æ€æ§åˆ¶
        self.mic_enabled = True

        # æ‰‹åŠ¨å½•éŸ³æ¨¡å¼
        self.manual_recording = False
        self.manual_frames = []
        self.last_result = None
        keyboard.add_hotkey('ctrl+j', self.toggle_manual)

        # VADæ¨¡å¼
        self.vad_audio_queue = Queue()
        self.vad_audio_frames = []
        self.vad_pre_buffer = []
        self.vad_is_recording = False
        self.vad_silence_timer = None
        self.vad_result_text = None
        self.vad_result_ready = threading.Event()
        self.vad_interrupt_audio = []
        self.vad_interrupt_detected = False
        self.vad_running = True
        self.vad_ws = None
        self.PRE_RECORD_TIME = 1
        self.PRE_BUFFER_SIZE = 16000 * self.PRE_RECORD_TIME

    def set_mic_enabled(self, enabled):
        """æ§åˆ¶éº¦å…‹é£å¼€å…³"""
        self.mic_enabled = enabled

    def send_audio_for_recognition(self, audio_data, is_bytes=False, print_result=False):
        """ç»Ÿä¸€çš„éŸ³é¢‘è¯†åˆ«å‡½æ•°"""
        audio_buffer = BytesIO()
        with wave.open(audio_buffer, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(16000)
            if is_bytes:
                wf.writeframes(audio_data)
            else:
                wf.writeframes((audio_data * 32767).astype(np.int16).tobytes())

        files = {"file": ("audio.wav", audio_buffer.getvalue(), "audio/wav")}
        response = requests.post("http://127.0.0.1:1000/v1/upload_audio", files=files)
        text = response.json()['text']

        return text

    def toggle_manual(self):
        """æ‰‹åŠ¨å½•éŸ³å¼€å…³"""
        self.manual_recording = not self.manual_recording
        if self.manual_recording:
            print("ğŸ™ï¸ æ‰‹åŠ¨å½•éŸ³å¼€å§‹...")
            self.manual_frames = []
        else:
            print("â¹ï¸ æ‰‹åŠ¨å½•éŸ³åœæ­¢")
            self.process_manual_audio()

    def process_manual_audio(self):
        """å¤„ç†æ‰‹åŠ¨å½•éŸ³"""
        if not self.manual_frames:
            return None
        audio_data = np.concatenate(self.manual_frames, axis=0)
        result = self.send_audio_for_recognition(audio_data, is_bytes=False, print_result=True)
        self.last_result = result
        return result

    def manual_callback(self, indata, frames, time, status):
        """æ‰‹åŠ¨å½•éŸ³å›è°ƒ"""
        if self.manual_recording:
            self.manual_frames.append(indata.copy())

    def vad_audio_callback(self, indata, frames, time, status):
        """VADéŸ³é¢‘å›è°ƒï¼ŒæŠŠæ•°æ®æ”¾åˆ°é˜Ÿåˆ—"""
        # æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å¯ç”¨
        if not self.mic_enabled:
            return

        audio_data = indata[:, 0].astype(np.float32)
        if len(audio_data) == 512:
            self.vad_audio_queue.put(audio_data)

    async def vad_process_audio(self):
        """VADå¤„ç†éŸ³é¢‘çš„å¼‚æ­¥å‡½æ•°"""
        uri = "ws://localhost:1000/v1/ws/vad"
        self.vad_ws = await websockets_client.connect(uri)

        while self.vad_running:
            try:
                if not self.vad_audio_queue.empty():
                    audio_data = self.vad_audio_queue.get()

                    # å‘é€éŸ³é¢‘æ•°æ®åˆ°VAD
                    await self.vad_ws.send(audio_data.tobytes())

                    # æ¥æ”¶VADç»“æœ
                    response = await self.vad_ws.recv()
                    result = json.loads(response)

                    if result["is_speech"]:
                        # æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å¯ç”¨
                        if not self.mic_enabled:
                            continue

                        # *** æ£€æµ‹éŸ³é¢‘æ’­æ”¾çŠ¶æ€æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰“æ–­ ***
                        import pygame
                        if pygame.mixer.get_init() and pygame.mixer.music.get_busy():
                            # åªæœ‰åœ¨å®æ—¶æ¨¡å¼ä¸‹æ‰æ‰“æ–­
                            if self.parent_neuro and self.parent_neuro.asr_real_time:
                                print("ğŸ”¥ğŸ”¥ğŸ”¥ æ£€æµ‹åˆ°äººå£°ï¼ŒéŸ³é¢‘æ­£åœ¨æ’­æ”¾ï¼Œç«‹å³æ‰“æ–­ï¼ğŸ”¥ğŸ”¥ğŸ”¥")

                                # åœæ­¢éŸ³é¢‘æ’­æ”¾
                                self.parent_neuro.audio_player.interrupt_audio()
                                # ä¹Ÿåœæ­¢æ–‡æœ¬ç”Ÿæˆ
                                self.parent_neuro.stop_flag = True
                                # é‡ç½®æƒ…ç»ªå¤„ç†å™¨
                                self.parent_neuro.emotion_handler.reset_buffer()

                                print("ğŸ¤ éŸ³é¢‘å·²è¢«æ‰“æ–­ï¼Œå¼€å§‹å½•åˆ¶ç”¨æˆ·è¯­éŸ³...")
                            else:
                                # éå®æ—¶æ¨¡å¼ä¸‹ï¼Œå¿½ç•¥äººå£°æ£€æµ‹
                                continue
                        else:
                            # åªåœ¨ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ°äººå£°æ—¶æ‰“å°çŠ¶æ€
                            if not self.vad_is_recording:
                                audio_playing = pygame.mixer.get_init() and pygame.mixer.music.get_busy() if pygame.mixer.get_init() else False
                                print(f"ğŸ¤ æ£€æµ‹åˆ°äººå£°! éŸ³é¢‘æ’­æ”¾çŠ¶æ€: {audio_playing}")

                        if self.vad_silence_timer:
                            self.vad_silence_timer.cancel()
                            self.vad_silence_timer = None

                        if not self.vad_is_recording:
                            self.vad_is_recording = True
                            print("ğŸ¤ å¼€å§‹å½•éŸ³...")
                            # æŠŠé¢„å½•éŸ³ç¼“å†²åŒºçš„æ•°æ®åŠ åˆ°å½•éŸ³å¼€å¤´
                            self.vad_audio_frames = self.vad_pre_buffer.copy()

                        # ä¿å­˜éŸ³é¢‘æ•°æ®
                        self.vad_audio_frames.append(audio_data.tobytes())

                    else:
                        # æ£€æµ‹åˆ°é™éŸ³
                        if self.vad_is_recording and not self.vad_silence_timer:
                            def end_vad_recording():
                                print("ğŸ¤ å½•éŸ³ç»“æŸï¼Œå¼€å§‹è¯†åˆ«...")
                                self.vad_is_recording = False
                                current_frames = self.vad_audio_frames

                                # åˆå¹¶éŸ³é¢‘æ•°æ®
                                if current_frames:
                                    audio_bytes = b''.join(current_frames)
                                    # è½¬æ¢ä¸º16ä½æ•´æ•°
                                    audio_float = np.frombuffer(audio_bytes, dtype=np.float32)
                                    audio_int16 = (audio_float * 32767).astype(np.int16)

                                    # å‘é€è¯†åˆ«
                                    try:
                                        text = self.send_audio_for_recognition(audio_int16.tobytes(), is_bytes=True,
                                                                               print_result=False)
                                        self.vad_result_text = text
                                        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")

                                    except Exception as e:
                                        print(f"è¯†åˆ«é”™è¯¯ï¼š{e}")
                                        self.vad_result_text = ""

                                # æ¸…ç©ºå¸§ç¼“å†²
                                self.vad_audio_frames = []
                                # è§¦å‘ç»“æœå°±ç»ªäº‹ä»¶
                                self.vad_result_ready.set()

                            self.vad_silence_timer = threading.Timer(0.5, end_vad_recording)
                            self.vad_silence_timer.start()

                    # æ›´æ–°é¢„å½•éŸ³ç¼“å†²åŒºï¼ˆåªæœ‰åœ¨éº¦å…‹é£å¯ç”¨æ—¶æ‰æ›´æ–°ï¼‰
                    if self.mic_enabled:
                        self.vad_pre_buffer.append(audio_data.tobytes())
                        # ä¿æŒç¼“å†²åŒºå¤§å°åœ¨1ç§’å†…
                        buffer_size = len(self.vad_pre_buffer) * 512
                        if buffer_size > self.PRE_BUFFER_SIZE:
                            # ç§»é™¤æœ€æ—§çš„æ•°æ®
                            remove_count = (buffer_size - self.PRE_BUFFER_SIZE) // 512
                            self.vad_pre_buffer = self.vad_pre_buffer[remove_count:]

                await asyncio.sleep(0.01)

            except Exception as e:
                print(f"VADå¤„ç†é”™è¯¯ï¼š{e}")
                break

        if self.vad_ws:
            await self.vad_ws.close()

    def vad_run_async_loop(self):
        """VADåœ¨åå°çº¿ç¨‹è¿è¡Œå¼‚æ­¥å¾ªç¯"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(self.vad_process_audio())

    def start_manual_mode(self):
        """å¯åŠ¨æ‰‹åŠ¨å½•éŸ³æ¨¡å¼"""
        print("æ‰‹åŠ¨æ¨¡å¼ï¼šæŒ‰ Ctrl+J å¼€å§‹/åœæ­¢å½•éŸ³")
        self.stream = sd.InputStream(callback=self.manual_callback, channels=1, samplerate=16000)
        self.stream.start()

    def stop_manual_mode(self):
        """åœæ­¢æ‰‹åŠ¨å½•éŸ³æ¨¡å¼"""
        if hasattr(self, 'stream'):
            self.stream.stop()

    async def start_vad_mode(self):
        """å¯åŠ¨VADè‡ªåŠ¨æ£€æµ‹æ¨¡å¼"""
        # å¯åŠ¨å½•éŸ³
        self.vad_stream = sd.InputStream(callback=self.vad_audio_callback,
                                         channels=1,
                                         samplerate=16000,
                                         blocksize=512)
        self.vad_stream.start()

        # å¯åŠ¨å¼‚æ­¥å¤„ç†çº¿ç¨‹
        async_thread = threading.Thread(target=self.vad_run_async_loop, daemon=True)
        async_thread.start()

        # ç­‰å¾…è¿æ¥å»ºç«‹
        time.sleep(0.5)

    def stop_vad_mode(self):
        """åœæ­¢VADæ¨¡å¼"""
        self.vad_running = False
        if hasattr(self, 'vad_stream'):
            self.vad_stream.stop()
            self.vad_stream.close()

    def simple_vad_detection(self):
        """ç®€å•çš„VADäººå£°æ£€æµ‹å‡½æ•°ï¼Œæ£€æµ‹åˆ°äººå£°å°±æ‰“å°æç¤º"""
        print("ğŸ¤ VADäººå£°æ£€æµ‹æ¨¡å¼å¯åŠ¨...")

        # åˆ›å»ºéŸ³é¢‘é˜Ÿåˆ—ç”¨äºVADæ£€æµ‹
        detection_queue = Queue()

        # æ·»åŠ çŠ¶æ€è·Ÿè¸ªï¼Œé¿å…é‡å¤æ‰“å°
        is_currently_speaking = False

        def detection_callback(indata, frames, time, status):
            """éŸ³é¢‘å›è°ƒå‡½æ•°"""
            audio_data = indata[:, 0].astype(np.float32)
            if len(audio_data) == 512:
                detection_queue.put(audio_data)

        async def vad_detection_process():
            """VADæ£€æµ‹å¤„ç†"""
            nonlocal is_currently_speaking
            uri = "ws://localhost:1000/v1/ws/vad"
            detection_ws = await websockets_client.connect(uri)

            try:
                while True:
                    if not detection_queue.empty():
                        audio_data = detection_queue.get()

                        # å‘é€éŸ³é¢‘æ•°æ®åˆ°VAD
                        await detection_ws.send(audio_data.tobytes())

                        # æ¥æ”¶VADç»“æœ
                        response = await detection_ws.recv()
                        result = json.loads(response)

                        if result["is_speech"]:
                            # åªæœ‰ä»é™éŸ³çŠ¶æ€è½¬æ¢åˆ°è¯´è¯çŠ¶æ€æ—¶æ‰æ‰“å°
                            if not is_currently_speaking:
                                print("å‡ºç°äº†äººå£°ï¼")
                                is_currently_speaking = True
                        else:
                            # æ£€æµ‹åˆ°é™éŸ³ï¼Œé‡ç½®çŠ¶æ€
                            is_currently_speaking = False

                    await asyncio.sleep(0.01)

            except KeyboardInterrupt:
                print("\næ£€æµ‹åœæ­¢")
            finally:
                await detection_ws.close()

        def run_detection():
            """è¿è¡Œæ£€æµ‹çš„å¼‚æ­¥å¾ªç¯"""
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(vad_detection_process())

        # å¯åŠ¨å½•éŸ³æµ
        detection_stream = sd.InputStream(callback=detection_callback,
                                          channels=1,
                                          samplerate=16000,
                                          blocksize=512)
        detection_stream.start()

        # å¯åŠ¨å¼‚æ­¥å¤„ç†çº¿ç¨‹
        detection_thread = threading.Thread(target=run_detection, daemon=True)
        detection_thread.start()

        try:
            print("äººå£°æ£€æµ‹è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\næ­£åœ¨åœæ­¢äººå£°æ£€æµ‹...")
            detection_stream.stop()
            detection_stream.close()

    def key_asr(self):
        while True:
            self.last_result = None
            self.start_manual_mode()
            # ç­‰å¾…ç”¨æˆ·å½•éŸ³å®Œæˆåè·å–ç»“æœ
            while not self.last_result:
                time.sleep(0.1)
            result_text = self.last_result
            print(f"ä½ : {result_text}")
            self.stop_manual_mode()
            return result_text

    def vad_asr(self):
        """VAD ASRä¸»å‡½æ•° - æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°åˆå§‹åŒ–çŠ¶æ€"""
        # å¦‚æœéº¦å…‹é£è¢«ç¦ç”¨ï¼Œç­‰å¾…å¯ç”¨
        while not self.mic_enabled:
            print("ğŸ”‡ éº¦å…‹é£å·²ç¦ç”¨ï¼Œç­‰å¾…å¯ç”¨...")
            time.sleep(0.5)

        # é‡ç½®æ‰€æœ‰çŠ¶æ€
        self.vad_result_text = None
        self.vad_result_ready.clear()
        self.vad_is_recording = False
        self.vad_audio_frames = []
        self.vad_running = True

        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.vad_audio_queue.empty():
            self.vad_audio_queue.get()

        # å¯åŠ¨VADæ¨¡å¼
        asyncio.run(self.start_vad_mode())
        print('ğŸ¤ VADæ¨¡å¼ï¼šå¼€å§‹å½•éŸ³ï¼Œè‡ªåŠ¨æ£€æµ‹è¯´è¯ï¼')

        # ç­‰å¾…å½•éŸ³ç»“æœ
        self.vad_result_ready.wait()
        result_text = self.vad_result_text

        # åœæ­¢VADæ¨¡å¼
        self.stop_vad_mode()

        return result_text


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é€‰æ‹©æ¨¡å¼
    audio = AudioSystem()

    # é€‰æ‹©æ¨¡å¼
    mode = input("é€‰æ‹©æ¨¡å¼ (1: æ‰‹åŠ¨å½•éŸ³, 2: VADè‡ªåŠ¨, 3: ç®€å•äººå£°æ£€æµ‹): ")

    if mode == "1":
        while True:
            audio.last_result = None
            audio.start_manual_mode()
            # ç­‰å¾…ç”¨æˆ·å½•éŸ³å®Œæˆåè·å–ç»“æœ
            while not audio.last_result:
                time.sleep(0.1)
            result_text = audio.last_result
            print(f"è·å–åˆ°çš„æ–‡æœ¬: {result_text}")
            audio.stop_manual_mode()
            # å¯é€‰ï¼šæ·»åŠ é€€å‡ºæœºåˆ¶
            if input("ç»§ç»­? (y/n): ").lower() != 'y':
                break
    elif mode == "2":
        while True:
            result_text = audio.vad_asr()
            print(f"è·å–åˆ°çš„æ–‡æœ¬: {result_text}")
    elif mode == "3":
        # æ–°çš„ç®€å•äººå£°æ£€æµ‹æ¨¡å¼
        audio.simple_vad_detection()
    else:
        print("æ— æ•ˆçš„æ¨¡å¼é€‰æ‹©")
